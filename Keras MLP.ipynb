{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:20:05.822956Z",
     "start_time": "2018-04-26T10:20:02.463587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:33:55.740316Z",
     "start_time": "2018-04-26T10:33:55.369787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#MNIST Loading\n",
    "\n",
    "batch_size = 128 \n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# One hot conversion\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we design the model. For now we are building a simple 2 layer network. Input is 784 pixels (MNIST), Hidden layer has 600 neurons and output has 10 classes (Digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:30:23.296497Z",
     "start_time": "2018-04-26T10:30:23.241535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 600)               471000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                6010      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 477,010\n",
      "Trainable params: 477,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# We are going to build a model with 2 layers 784x600x10 labels\n",
    "###Model###\n",
    "model.add(Dense(600, input_dim=784)) #We are adding one Dense Layer (input * W + b)\n",
    "model.add(Activation('sigmoid')) #We are adding a sigmoid activation. \n",
    "\n",
    "model.add(Dense(10)) #We are adding one final layer for predicting the 10 classes.\n",
    "model.add(Activation('softmax'))\n",
    "model.summary() #Shows the summary of your model design. Use this a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:35:05.899569Z",
     "start_time": "2018-04-26T10:34:33.213813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0185 - acc: 0.8863 - val_loss: 0.0121 - val_acc: 0.9214\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0111 - acc: 0.9287 - val_loss: 0.0096 - val_acc: 0.9391\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0089 - acc: 0.9427 - val_loss: 0.0084 - val_acc: 0.9456\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0075 - acc: 0.9531 - val_loss: 0.0072 - val_acc: 0.9527\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0063 - acc: 0.9602 - val_loss: 0.0063 - val_acc: 0.9594\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0054 - acc: 0.9671 - val_loss: 0.0055 - val_acc: 0.9647\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0046 - acc: 0.9724 - val_loss: 0.0053 - val_acc: 0.9670\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0041 - acc: 0.9760 - val_loss: 0.0046 - val_acc: 0.9712\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0035 - acc: 0.9794 - val_loss: 0.0044 - val_acc: 0.9716\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0031 - acc: 0.9820 - val_loss: 0.0042 - val_acc: 0.9727\n",
      "Test loss: 0.004221907087972795\n",
      "Test accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "#If you want to checkout Tensorboard uncomment the next line and add a parameter : callbacks=[tfcall] in your model.fit\n",
    "#tfcall = keras.callbacks.TensorBoard(log_dir='./keras600logs', histogram_freq=1, batch_size=batch_size, write_graph=True)\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['accuracy']) #We will use a slightly more advanced optimiser call Adam. We can discuss how it works in later classes.\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=10, #EPOCHS\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "                    #callbacks=[tfcall]) #For Tensorboard\n",
    "score = model.evaluate(x_test, y_test, verbose=0) #Predict on a test dataset and see how well does this model do on that. \n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
