{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "__author__ = \"Martin Mbaya\"\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Activation, Dropout\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function that opens the csv file \"prima_indians.csv\". The labels are separated from the variables then normalized by subtracting the mean from each value.\n",
    "The data is then split into training and testing portions to be used by the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    data_set = pd.read_csv(\"prima_indians.csv\")\n",
    "    # print(data_set.head())\n",
    "    # print(data_set.columns)\n",
    "    y = data_set.pop(\" Class\")\n",
    "    x = data_set\n",
    "    x -= np.mean(x, axis = 0)\n",
    "    # print(x.head())\n",
    "    # print(x.columns)\n",
    "\n",
    "    # y = data_set.pop(\" Class\")\n",
    "    # x = data_set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "    # print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    X_train = np.array(x_train).astype('float32')\n",
    "    X_test = np.array(x_test).astype('float32')\n",
    "    Y_train = keras.utils.to_categorical(y_train, 2)\n",
    "    Y_test = keras.utils.to_categorical(y_test, 2)\n",
    "    # print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-layer Neural Network is then created below.\n",
    "Hyperparameter tuning is done using the module called Hyperas through enclosing options for each of the parameters in \"{{ }}\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "    NB_EPOCH = 100\n",
    "    # BATCH_SIZE = 512\n",
    "    VERBOSE = 0\n",
    "    NB_CLASSES = 2   # number of outputs = number of digits\n",
    "    OPTIMIZER = 'RMSprop'\n",
    "    RESHAPED = len(x_test.columns)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([256, 512, 1024, 2048])}}, input_dim=RESHAPED, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2({{uniform(0,1)}})))\n",
    "    model.add(Activation({{choice(['sigmoid', 'relu'])}}))\n",
    "    # model.add(Activation('sigmoid'))\n",
    "#     model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Dense(2)) \n",
    "    model.add(Activation({{choice(['softmax', 'linear'])}}))\n",
    "    # model.add(Activation('softmax'))\n",
    "    # model.summary() \n",
    "    model.compile(loss={{choice(['categorical_crossentropy', 'mse'])}} ,optimizer={{choice(['RMSprop', 'Adam', 'sgd'])}}, metrics=['accuracy']) \n",
    "    # model.compile(loss='mse' ,optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size={{choice([64,128,512,1024])}},\n",
    "                        epochs=NB_EPOCH, #EPOCHS\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test, Y_test))\n",
    "                        #callbacks=[tfcall]) #For Tensorboard\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    # print('Test loss:', score[0])\n",
    "    # print('Test accuracy:', score[1])\n",
    "#     print(\"Model run complete..\")\n",
    "    return {'loss': -score[1], 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of number of neurons in the first layer, float value used by the l2 regularizer, activation functions, loss functions, optimizer and batch size is done using the Hyperas module.\n",
    "The Tree-structured Parzen Estimator (TPE) algorithm, which explores intelligently the search space while narrowing down to the estimated best parameters is used for optimization.\n",
    "The optimization is repeated over and over again, while keeping only the highest score until it either breaks the 85% mark or no improvement is observed over 10 iterations. At this point, the best overall model is selected, saved and its score printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 109us/step\n",
      "231/231 [==============================] - 0s 104us/step\n",
      "231/231 [==============================] - 0s 117us/step\n",
      "231/231 [==============================] - 0s 143us/step\n",
      "231/231 [==============================] - 0s 117us/step\n",
      "231/231 [==============================] - 0s 152us/step\n",
      "231/231 [==============================] - 0s 124us/step\n",
      "231/231 [==============================] - 0s 208us/step\n",
      "231/231 [==============================] - 0s 158us/step\n",
      "231/231 [==============================] - 0s 148us/step\n",
      "231/231 [==============================] - 0s 184us/step\n",
      "231/231 [==============================] - 0s 150us/step\n",
      "231/231 [==============================] - 0s 184us/step\n",
      "231/231 [==============================] - 0s 406us/step\n",
      "231/231 [==============================] - 0s 163us/step\n",
      "231/231 [==============================] - 0s 156us/step\n",
      "231/231 [==============================] - 0s 306us/step\n",
      "231/231 [==============================] - 0s 157us/step\n",
      "231/231 [==============================] - 0s 171us/step\n",
      "231/231 [==============================] - 0s 165us/step\n",
      "231/231 [==============================] - 0s 189us/step\n",
      "231/231 [==============================] - 0s 230us/step\n",
      "231/231 [==============================] - 0s 229us/step\n",
      "231/231 [==============================] - 0s 198us/step\n",
      "Test loss: 0.9810078814948276\n",
      "Test accuracy: 84.8484849000906  %\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "highest_score = [0.0, 0.0]\n",
    "current_score = [0.0, 0.0]\n",
    "while True:\n",
    "    if highest_score[1] < 0.85:\n",
    "        X_train, Y_train, X_test, Y_test = data()\n",
    "\n",
    "        best_run, best_model = optim.minimize(model=model,\n",
    "                                                data=data,\n",
    "                                                algo=tpe.suggest,\n",
    "                                                max_evals=10,\n",
    "                                                verbose=False,\n",
    "                                                trials=Trials(),\n",
    "                                              notebook_name='Assignment 2 - Hyperas')\n",
    "\n",
    "        current_score = best_model.evaluate(X_test, Y_test)\n",
    "        if current_score[1] > highest_score[1]:\n",
    "            model_json = best_model.to_json()\n",
    "            open('prima_indians.json', 'w').write(model_json)\n",
    "            best_model.save_weights('prima_indians.h5', overwrite=True)\n",
    "            highest_score = current_score\n",
    "            fail_count = 0\n",
    "        else:\n",
    "            if fail_count > 10:\n",
    "                print('Test loss:', highest_score[0])\n",
    "                print('Test accuracy:', (highest_score[1]*100), \" %\")\n",
    "                break\n",
    "            fail_count += 1\n",
    "    else:\n",
    "        print(\"Evaluation of best performing model: \")\n",
    "        # print(highest_score, \"\\n\")\n",
    "        print('Test loss:', highest_score[0])\n",
    "        print('Test accuracy:', (highest_score[1]*100), \" %\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
